{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/trieuduongle/FLAVR/blob/generative-approach/Training_FLAVR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "holsmMm9K7ZW",
        "outputId": "d9394198-9e7f-4e8c-c345-557098581fa6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/trieuduongle/FLAVR.git '/content/drive/My Drive/Duong/FLAVR/code'"
      ],
      "metadata": {
        "id": "zpiLPPDiM6xQ",
        "outputId": "7750c55e-61aa-4500-f56f-f85c442ccd48",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into '/content/drive/My Drive/Duong/FLAVR/code'...\n",
            "remote: Enumerating objects: 296, done.\u001b[K\n",
            "remote: Counting objects: 100% (37/37), done.\u001b[K\n",
            "remote: Compressing objects: 100% (15/15), done.\u001b[K\n",
            "remote: Total 296 (delta 28), reused 22 (delta 22), pack-reused 259\u001b[K\n",
            "Receiving objects: 100% (296/296), 33.80 MiB | 17.45 MiB/s, done.\n",
            "Resolving deltas: 100% (161/161), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.flush_and_unmount()"
      ],
      "metadata": {
        "id": "PSc08l6CdfC-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd '/content/drive/My Drive/Duong/FLAVR/code'"
      ],
      "metadata": {
        "id": "JzGeXaRVNIQj",
        "outputId": "aa843c73-fe9d-473e-a5bc-6504b4c77b54",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/Duong/FLAVR/code\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git fetch origin && git checkout generative-approach && git pull"
      ],
      "metadata": {
        "id": "V8NdXX4-NSEa",
        "outputId": "2c96c5ce-de6d-4f9d-910e-01b1e8c2d250",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "remote: Enumerating objects: 5, done.\u001b[K\n",
            "remote: Counting objects:  20% (1/5)\u001b[K\rremote: Counting objects:  40% (2/5)\u001b[K\rremote: Counting objects:  60% (3/5)\u001b[K\rremote: Counting objects:  80% (4/5)\u001b[K\rremote: Counting objects: 100% (5/5)\u001b[K\rremote: Counting objects: 100% (5/5), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1/1)\u001b[K\rremote: Compressing objects: 100% (1/1), done.\u001b[K\n",
            "remote: Total 3 (delta 2), reused 3 (delta 2), pack-reused 0\u001b[K\n",
            "Unpacking objects:  33% (1/3)   \rUnpacking objects:  66% (2/3)   \rUnpacking objects: 100% (3/3)   \rUnpacking objects: 100% (3/3), done.\n",
            "From https://github.com/trieuduongle/FLAVR\n",
            "   1327b9d..47a6de2  generative-approach -> origin/generative-approach\n",
            "Already on 'generative-approach'\n",
            "Your branch is behind 'origin/generative-approach' by 1 commit, and can be fast-forwarded.\n",
            "  (use \"git pull\" to update your local branch)\n",
            "Updating 1327b9d..47a6de2\n",
            "Fast-forward\n",
            " config.py | 1 \u001b[32m+\u001b[m\n",
            " 1 file changed, 1 insertion(+)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py --batch_size 12 --test_batch_size 12 --dataset vimeo90K_septuplet --loss 1*L1 --max_epoch 200 --lr 0.0002 --data_root \"/content/drive/My Drive/Duong/datasets/vimeo-septuplet\" --n_outputs 1"
      ],
      "metadata": {
        "id": "A6bwjpCOQAN9",
        "outputId": "97cdb563-b9fe-427c-c21b-9e2f4846b111",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(batch_size=12, beta1=0.9, beta2=0.99, checkpoint_dir='.', cuda=True, data_root='/content/drive/My Drive/Duong/datasets/vimeo-septuplet', dataset='vimeo90K_septuplet', exp_name='exp', joinType='concat', load_from=None, log_iter=60, loss='1*L1', lr=0.0002, max_epoch=200, model='unet_18', n_outputs=1, nbr_frame=4, nbr_width=1, num_gpu=1, num_workers=16, pretrained=None, random_seed=12345, resume=False, resume_exp=None, start_epoch=0, test_batch_size=12, upmode='transpose', use_tensorboard=False, val_freq=1)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Building model: unet_18\n",
            "Preparing loss function:\n",
            "1.000 * L1\n",
            "Train Epoch: 0 [0/652]\tLoss: 0.179622\tPSNR: 13.8431\n",
            "Train Epoch: 0 [60/652]\tLoss: 0.162781\tPSNR: 13.7569\n",
            "Train Epoch: 0 [120/652]\tLoss: 0.158649\tPSNR: 13.7712\n",
            "Train Epoch: 0 [180/652]\tLoss: 0.163415\tPSNR: 15.6776\n",
            "Train Epoch: 0 [240/652]\tLoss: 0.162338\tPSNR: 16.0644\n",
            "Train Epoch: 0 [300/652]\tLoss: 0.160312\tPSNR: 13.9548\n",
            "Train Epoch: 0 [360/652]\tLoss: 0.160800\tPSNR: 13.9924\n",
            "Train Epoch: 0 [420/652]\tLoss: 0.159939\tPSNR: 13.9037\n",
            "Train Epoch: 0 [480/652]\tLoss: 0.154992\tPSNR: 13.3776\n",
            "Train Epoch: 0 [540/652]\tLoss: 0.157987\tPSNR: 15.3511\n",
            "Train Epoch: 0 [600/652]\tLoss: 0.163689\tPSNR: 12.8176\n",
            "Evaluating for epoch = 0\n",
            "100% 652/652 [42:48<00:00,  3.94s/it]\n",
            "Loss: 0.065172, PSNR: 20.878301, SSIM: 0.683192\n",
            "\n",
            "Train Epoch: 1 [0/652]\tLoss: 0.203493\tPSNR: 12.8654\n",
            "Train Epoch: 1 [60/652]\tLoss: 0.162411\tPSNR: 15.4833\n",
            "Train Epoch: 1 [120/652]\tLoss: 0.159592\tPSNR: 13.4789\n",
            "Train Epoch: 1 [180/652]\tLoss: 0.157330\tPSNR: 17.7058\n",
            "Train Epoch: 1 [240/652]\tLoss: 0.160416\tPSNR: 14.2433\n",
            "Train Epoch: 1 [300/652]\tLoss: 0.157954\tPSNR: 14.1674\n",
            "Train Epoch: 1 [360/652]\tLoss: 0.158478\tPSNR: 14.1987\n",
            "Train Epoch: 1 [420/652]\tLoss: 0.159601\tPSNR: 14.0368\n",
            "Train Epoch: 1 [480/652]\tLoss: 0.159808\tPSNR: 13.9506\n",
            "Train Epoch: 1 [540/652]\tLoss: 0.156348\tPSNR: 14.1501\n",
            "Train Epoch: 1 [600/652]\tLoss: 0.153982\tPSNR: 13.5809\n",
            "Evaluating for epoch = 1\n",
            "100% 652/652 [42:28<00:00,  3.91s/it]\n",
            "Loss: 0.093072, PSNR: 17.759996, SSIM: 0.669507\n",
            "\n",
            "Train Epoch: 2 [0/652]\tLoss: 0.175017\tPSNR: 13.0664\n",
            "Train Epoch: 2 [60/652]\tLoss: 0.159691\tPSNR: 16.8441\n",
            "Train Epoch: 2 [120/652]\tLoss: 0.162333\tPSNR: 13.3147\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python Middleburry_Test.py \\\n",
        "  --data_root \"/content/drive/My Drive/Duong/datasets/middleburry/test\" \\\n",
        "  --load_from \"/content/drive/MyDrive/Duong/FLAVR/code/saved_models_final/vimeo90K_septuplet/exp/model_best.pth\" \\\n",
        "  --n_outputs 1"
      ],
      "metadata": {
        "id": "PpwMmxXbc06p",
        "outputId": "77084f84-98ac-498b-872a-b5510031b7c3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Building model: unet_18\n",
            "#params 42061571\n",
            "Time Taken 5.65799880027771\n",
            "Time Taken 0.008217096328735352\n",
            "Time Taken 0.0075435638427734375\n",
            "Time Taken 0.0077114105224609375\n",
            "Time Taken 0.007925271987915039\n",
            "Time Taken 0.010061979293823242\n",
            "Time Taken 0.009283065795898438\n",
            "Time Taken 0.007558584213256836\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python Middleburry_Test.py \\\n",
        "  --data_root \"/content/drive/My Drive/Duong/datasets/middleburry/test\" \\\n",
        "  --load_from \"/content/drive/MyDrive/Duong/FLAVR/code/FLAVR_2x.pth\" \\\n",
        "  --n_outputs 1"
      ],
      "metadata": {
        "id": "fVhIQR89scqb",
        "outputId": "64c7cd32-af74-4155-a835-ec7d5a74cd5c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Building model: unet_18\n",
            "#params 42061571\n",
            "Traceback (most recent call last):\n",
            "  File \"Middleburry_Test.py\", line 104, in <module>\n",
            "    main(args)\n",
            "  File \"Middleburry_Test.py\", line 100, in main\n",
            "    test(args)\n",
            "  File \"Middleburry_Test.py\", line 79, in test\n",
            "    out = model(images)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/parallel/data_parallel.py\", line 166, in forward\n",
            "    return self.module(*inputs[0], **kwargs[0])\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/content/drive/MyDrive/Duong/FLAVR/code/model/FLAVR_arch.py\", line 153, in forward\n",
            "    x_0 , x_1 , x_2 , x_3 , x_4 = self.encoder(images)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/content/drive/MyDrive/Duong/FLAVR/code/model/resnet_3D.py\", line 184, in forward\n",
            "    x_0 = self.stem(x)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\", line 139, in forward\n",
            "    input = module(input)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\", line 607, in forward\n",
            "    return self._conv_forward(input, self.weight, self.bias)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\", line 603, in _conv_forward\n",
            "    input, weight, bias, self.stride, self.padding, self.dilation, self.groups\n",
            "KeyboardInterrupt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git pull && python main.py \\\n",
        "  --batch_size 10 \\\n",
        "  --test_batch_size 10 \\\n",
        "  --dataset vimeo90K_septuplet \\\n",
        "  --loss 1*GAN \\\n",
        "  --checkpoint_dir integrate_gan \\\n",
        "  --patch_size 256 \\\n",
        "  --max_epoch 200 \\\n",
        "  --lr 0.0002 \\\n",
        "  --data_root \"/content/drive/My Drive/Duong/datasets/vimeo-septuplet\" \\\n",
        "  --n_outputs 1"
      ],
      "metadata": {
        "id": "nkm91s87z6KA",
        "outputId": "44f2a97a-05e6-4009-ba2e-d1c0e47fd8ec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Already up to date.\n",
            "Namespace(batch_size=10, beta1=0.9, beta2=0.99, checkpoint_dir='integrate_gan', cuda=True, data_root='/content/drive/My Drive/Duong/datasets/vimeo-septuplet', dataset='vimeo90K_septuplet', exp_name='exp', joinType='concat', load_from=None, log_iter=60, loss='1*GAN', lr=0.0002, max_epoch=200, model='unet_18', n_outputs=1, nbr_frame=4, nbr_width=1, num_gpu=1, num_workers=16, patch_size=256, pretrained=None, random_seed=12345, resume=False, resume_exp=None, start_epoch=0, test_batch_size=10, upmode='transpose', use_tensorboard=False, val_freq=1)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Building model: unet_18\n",
            "Preparing loss function:\n",
            "1.000 * GAN\n",
            "images\n",
            "4 torch.Size([10, 3, 256, 256])\n",
            "1 torch.Size([10, 3, 256, 256])\n",
            "4 torch.Size([10, 3, 256, 256])\n",
            "10 torch.Size([3, 256, 256])\n",
            "calling\n",
            "[10, 3, 256, 256]\n",
            "[10, 3, 256, 256]\n",
            "extra_vars\n",
            "hello\n",
            "Train Epoch: 0 [0/783]\tLoss: 13.176337\tPSNR: 15.1716\n",
            "images\n",
            "4 torch.Size([10, 3, 256, 256])\n",
            "1 torch.Size([10, 3, 256, 256])\n",
            "4 torch.Size([10, 3, 256, 256])\n",
            "10 torch.Size([3, 256, 256])\n",
            "calling\n",
            "[10, 3, 256, 256]\n",
            "[10, 3, 256, 256]\n",
            "extra_vars\n",
            "hello\n",
            "images\n",
            "4 torch.Size([10, 3, 256, 256])\n",
            "1 torch.Size([10, 3, 256, 256])\n",
            "4 torch.Size([10, 3, 256, 256])\n",
            "10 torch.Size([3, 256, 256])\n",
            "calling\n",
            "[10, 3, 256, 256]\n",
            "[10, 3, 256, 256]\n",
            "extra_vars\n",
            "hello\n",
            "Traceback (most recent call last):\n",
            "  File \"main.py\", line 216, in <module>\n",
            "    main(args)\n",
            "  File \"main.py\", line 197, in main\n",
            "    train(args, epoch)\n",
            "  File \"main.py\", line 85, in train\n",
            "    images = [img_.cuda() for img_ in images]\n",
            "  File \"main.py\", line 85, in <listcomp>\n",
            "    images = [img_.cuda() for img_ in images]\n",
            "KeyboardInterrupt\n"
          ]
        }
      ]
    }
  ]
}